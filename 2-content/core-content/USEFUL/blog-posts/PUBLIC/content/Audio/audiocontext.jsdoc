AudioContext : EventTarget

AudioContext represents the sound system of the computer and
is the main object used for creating and managing
audio.
Audio is generated by a set of %%/AudioNode|AudioNodes%% 
that are combined and routed to the %%AudioDestinationNode|AudioDestinationNode%%.



Spec:
http://www.w3.org/TR/2013/WD-webaudio-20131010/#AudioContext-section

----
new AudioContext() : AudioContext

----
instance.destination : AudioDestinationNode

ReadOnly:
true

----
instance.sampleRate : Number

ReadOnly:
true

----
instance.currentTime : Number

ReadOnly:
true

----
instance.listener : AudioListener

ReadOnly:
true

----
prototype.createBuffer(numberOfChannels : Number, length : Number, sampleRate : Number) : AudioBuffer

----
prototype.decodeAudioData(audioData : ArrayBuffer, successCallback(decodedData : AudioBuffer) : undefined, [errorCallback() : undefined]) : undefined

----
prototype.createBufferSource() : AudioBufferSourceNode

----
prototype.createMediaElementSource(mediaElement : HTMLMediaElement) : MediaElementAudioSourceNode

----
prototype.createMediaStreamSource(mediaStream : MediaStream) : MediaStreamAudioSourceNode

----
prototype.createMediaStreamDestination() : MediaStreamAudioDestinationNode

----
prototype.createScriptProcessor([bufferSize = 0 : Number, [numberOfInputChannels = 2 : Number, [numberOfOutputChannels = 2 : Number]]]) : ScriptProcessorNode

----
prototype.createAnalyser() : AnalyserNode

----
prototype.createGain() : GainNode

----
prototype.createDelay([maxDelayTime = 1.0 : Number]) : DelayNode


<htmlexample>
<!-- Delay the audio by 2 seconds -->
<video id='video' src='fireworks.ogv' width='150' height='100'></video><br>
<button onclick='video.paused ? video.play() : video.pause()'>Play/Pause</button>
<script>
  var video = document.getElementById('video');

  // Try AudioContext and fall back to webkitAudioContext if AudioContext isn't available
  var context = new (window.AudioContext || window.webkitAudioContext)();

  // Create an audio node from the video's audio track
  var source = context.createMediaElementSource(video);

  // Create a reverb node to delay the audio
  var reverb = context.createDelay(2);
  reverb.delayTime.value = 2;

  // Connect source node to reverb node
  source.connect(reverb);

  // Connect the reverb node to the destination (output) node
  reverb.connect(context.destination);
</script>
</htmlexample>

----
prototype.createBiquadFilter() : BiquadFilterNode

----
prototype.createWaveShaper() : WaveShaperNode

----
prototype.createPanner() : PannerNode

----
prototype.createConvolver() : ConvolverNode

----
prototype.createChannelSplitter([numberOfOutputs = 6 : Number]) : ChannelSplitterNode

----
prototype.createChannelMerger([numberOfInputs = 6 : Number]) : ChannelMergerNode

----
prototype.createDynamicsCompressor() : DynamicsCompressorNode

----
prototype.createOscillator() : OscillatorNode

----
prototype.createPeriodicWave(real : Float32Array, imaginary : Float32Array) : PeriodicWave

